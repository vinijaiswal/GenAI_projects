{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💼 Build a TariffIQ Chat Agent — Haystack x OpenAI\n",
    "\n",
    "📚 Welcome to this hands-on hackathon notebook! \n",
    "In this tutorial, you'll build a **chat agent that answers real-world tariff-related questions**, product exemptions, and executive order impacts — using Haystack and OpenAI's function calling.\n",
    "\n",
    "### 💡 Why This Matters:\n",
    "Global trade is complex. This app helps businesses **ask questions** and get **answers** from structured data and real documents.\n",
    "\n",
    "---\n",
    "### 1. 🧰 What You’ll Learn:\n",
    "In this tutorial, you'll learn how to convert your Haystack pipeline into a function-calling tool and how to implement applications using OpenAI's Chat Completion API through `OpenAIChatGenerator` for agent-like behavior.\n",
    "\n",
    "- Embed documents with Haystack\n",
    "- Build a Retrieval-Augmented Generator (RAG)\n",
    "- Use OpenAI to call functions (aka tools)\n",
    "- Deploy a smart chatbot via Gradio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Info\n",
    "- **Level**: Advanced\n",
    "- **Time to complete**: 20 minutes\n",
    "- **Components Used**: [InMemoryDocumentStore](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore), [SentenceTransformersDocumentEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder), [SentenceTransformersTextEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder), [InMemoryEmbeddingRetriever](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever), [ChatPromptBuilder](https://docs.haystack.deepset.ai/docs/chatpromptbuilder), [OpenAIChatGenerator](https://docs.haystack.deepset.ai/docs/openaichatgenerator), [ToolInvoker](https://docs.haystack.deepset.ai/docs/toolinvoker)\n",
    "- **Prerequisites**: You must have an [OpenAI API Key](https://platform.openai.com/api-keys) and be familiar with [creating pipelines](https://docs.haystack.deepset.ai/docs/creating-pipelines)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PWXXqq_MPn7y"
   },
   "source": [
    "\n",
    "#### 📚 Useful Sources:\n",
    "* [OpenAIChatGenerator Docs](https://docs.haystack.deepset.ai/docs/openaichatgenerator)\n",
    "* [OpenAIChatGenerator API Reference](https://docs.haystack.deepset.ai/reference/generator-api#openaichatgenerator)\n",
    "* [🧑‍🍳 Cookbooks](https://github.com/deepset-ai/haystack-cookbook/blob/main/notebooks/)\n",
    "\n",
    "[OpenAI's function calling](https://platform.openai.com/docs/guides/function-calling) connects large language models to external tools. By providing a `tools` list with functions and their specifications to the OpenAI API calls, you can easily build chat assistants that can answer questions by calling external APIs or extract structured information from text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K04cnh_IleMV"
   },
   "source": [
    "### 2. ⚙️ Setting up the Development Environment\n",
    "\n",
    "Install Haystack and [sentence-transformers](https://pypi.org/project/sentence-transformers/) using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "zNyqNVFaPN1A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haystack-ai in /opt/homebrew/lib/python3.11/site-packages (2.11.2)\n",
      "Requirement already satisfied: haystack-experimental in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (0.8.0)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (3.1.5)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (0.4.0)\n",
      "Requirement already satisfied: more-itertools in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (10.6.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (3.4.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (1.25.0)\n",
      "Requirement already satisfied: openai>=1.56.1 in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (1.68.2)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (3.21.0)\n",
      "Requirement already satisfied: pydantic in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (2.10.6)\n",
      "Requirement already satisfied: python-dateutil in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (9.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/lib/python3.11/site-packages (from haystack-ai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai>=1.56.1->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.11/site-packages (from posthog!=3.12.0->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->haystack-ai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->haystack-ai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->haystack-ai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->haystack-ai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->haystack-ai) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->haystack-ai) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->haystack-ai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->haystack-ai) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->haystack-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->haystack-ai) (0.23.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (0.14.0)\n",
      "Requirement already satisfied: sentence-transformers>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (0.28.1)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers>=3.0.0) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=3.0.0) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (1.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=3.0.0) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install haystack-ai\n",
    "pip install \"sentence-transformers>=3.0.0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XwlBLN-GwuuU"
   },
   "source": [
    "### Enable Telemetry [Optional]\n",
    "\n",
    "Knowing you're using this tutorial helps us decide where to invest our efforts to build a better product but you can always opt out by commenting the following line. See [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V0-VuEgwt2u"
   },
   "outputs": [],
   "source": [
    "# from haystack.telemetry import tutorial_running\n",
    "\n",
    "# tutorial_running(40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2owelT4NpXtw"
   },
   "source": [
    "### 3. 🔐 OpenAI Setup\n",
    "Save your OpenAI API key as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM-sVkYonutA",
    "outputId": "7895e2b4-97a3-4cfe-e2cc-80bceac53b3e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 🧱 Document Embedding (Tariff Docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Documents with a Pipeline\n",
    "\n",
    "Create a pipeline to store the small example dataset in the [InMemoryDocumentStore](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore) with their embeddings. You will use [SentenceTransformersDocumentEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder) to generate embeddings for your Documents and write them to the document store with the [DocumentWriter](https://docs.haystack.deepset.ai/docs/documentwriter).\n",
    "\n",
    "After adding these components to your pipeline, connect them and run the pipeline.\n",
    "\n",
    "> If you'd like to learn about preprocessing files before you index them to your document store, follow the [Preprocessing Different File Types](https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "# Initialize document store\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📜 Executive Order sample\n",
    "eo_doc = Document(\n",
    "    content=(\n",
    "        \"Section 2: Effective April 2025, a 20% tariff will be applied to electronic components \"\n",
    "        \"imported from select non-domestic regions. Section 4: HS Codes 8542.31 and 8542.33 are \"\n",
    "        \"explicitly mentioned in the scope of this order.\"\n",
    "    ),\n",
    "    meta={\"source\": \"EO_2025_Tariffs.pdf\", \"type\": \"executive_order\"}\n",
    ")\n",
    "\n",
    "# 🏢 Internal Supplier/Product Data\n",
    "internal_doc = Document(\n",
    "    content=(\n",
    "        \"Product: ARM Cortex-M4 SoC\\n\"\n",
    "        \"HS Code: 8542.31.0000\\n\"\n",
    "        \"Supplier: Global Embedded Systems Ltd.\\n\"\n",
    "        \"Region of Origin: Southeast Asia\\n\"\n",
    "        \"Quantity: 5,000 units\\n\"\n",
    "        \"Unit Cost: $18.25\"\n",
    "    ),\n",
    "    meta={\"source\": \"Q1_supplier_list.csv\", \"type\": \"internal_supplier_data\"}\n",
    ")\n",
    "\n",
    "# 📚 Tariff Schedule Entry\n",
    "tariff_schedule_doc = Document(\n",
    "    content=(\n",
    "        \"HS Code 8542.31.0000 refers to: Electronic integrated circuits as processors and controllers, \"\n",
    "        \"whether or not combined with memory. Current duty rate: 0%. Subject to change under recent trade updates.\"\n",
    "    ),\n",
    "    meta={\"source\": \"HTS_2025.csv\", \"type\": \"tariff_schedule\"}\n",
    ")\n",
    "\n",
    "# 📰 Trade News Sample\n",
    "news_doc = Document(\n",
    "    content=(\n",
    "        \"Trade analysts report that recent executive orders may increase tariffs on selected categories of \"\n",
    "        \"microelectronics, with potential implications for global suppliers in the embedded systems industry.\"\n",
    "    ),\n",
    "    meta={\"source\": \"industry_news_march2025.txt\", \"type\": \"trade_news\"}\n",
    ")\n",
    "\n",
    "# 🧺 Final list of documents\n",
    "documents = [eo_doc, internal_doc, tariff_schedule_doc, news_doc]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build a RAG Pipeline\n",
    "\n",
    "Build a basic retrieval augmented generative pipeline with [SentenceTransformersTextEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder), [InMemoryEmbeddingRetriever](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever), [ChatPromptBuilder](https://docs.haystack.deepset.ai/docs/chatpromptbuilder) and [OpenAIChatGenerator](https://docs.haystack.deepset.ai/docs/openaichatgenerator).\n",
    "\n",
    "> For a step-by-step guide to create a RAG pipeline with Haystack, follow the [Creating Your First QA Pipeline with Retrieval-Augmentation](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 4}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "\n",
    "# Run the pipeline to store embedded documents\n",
    "pipeline.run(data={\"embedder\": {\"documents\": documents}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💬 Build the Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x39edf9f90>\n",
       "🚅 Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - chat_generator: OpenAIChatGenerator\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> chat_generator.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.utils import Secret\n",
    "template = [\n",
    "    ChatMessage.from_user(\n",
    "    \"\"\"\n",
    "    Given the following information, answer the question.\n",
    "\n",
    "    Context:\n",
    "    {% for document in documents %}\n",
    "        {{ document.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    Question: {{question}}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    )\n",
    "]\n",
    "prompt_builder = ChatPromptBuilder(template=template)\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\", api_key=Secret.from_env_var(\"OPENAI_API_KEY\"))\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"chat_generator\", chat_generator)\n",
    "\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder.prompt\", \"chat_generator.messages\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 🔍 Create a Tool from a Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `rag_pipeline_tool`, create a new tool called `get_tariff_info` to be used to get  tariff information from the manually created database.\n",
    "\n",
    "First, create a function that simulates an API call to tariff information database. Instead of passing parameters as JSON (like in the previous tool), use [`create_tool_from_function`](https://docs.haystack.deepset.ai/docs/tool#create_tool_from_function). This function requires additional details using the `Annotated` type to describe tool parameters. However, based on this information, `create_tool_from_function` can automatically infer the parameters and generate a JSON schema, so you don't need to define `parameters` separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from haystack.tools import create_tool_from_function\n",
    "\n",
    "TARIFF_DATA = {\n",
    "    \"8542.31\": {\n",
    "        \"product\": \"Electronic integrated circuits - processors and controllers\",\n",
    "        \"tariff_rate\": \"25%\",\n",
    "        \"effective_date\": \"2025-04-01\",\n",
    "        \"included_in_eo\": True\n",
    "    },\n",
    "    \"8542.33\": {\n",
    "        \"product\": \"Electronic integrated circuits - amplifiers\",\n",
    "        \"tariff_rate\": \"15%\",\n",
    "        \"effective_date\": \"2025-04-01\",\n",
    "        \"included_in_eo\": True\n",
    "    },\n",
    "    \"9018.39\": {\n",
    "        \"product\": \"Medical diagnostic equipment\",\n",
    "        \"tariff_rate\": \"0%\",\n",
    "        \"effective_date\": \"2025-04-01\",\n",
    "        \"included_in_eo\": False\n",
    "    }\n",
    "}\n",
    "def get_tariff_info(\n",
    "    hs_code: Annotated[str, \"The HS Code of the product (e.g., 8542.31)\"] = \"8542.31\",\n",
    "):\n",
    "    \"\"\"Returns tariff information for a given HS code.\"\"\"\n",
    "    data = TARIFF_DATA.get(hs_code)\n",
    "    if data:\n",
    "        return data\n",
    "    else:\n",
    "        return {\n",
    "            \"product\": \"Unknown product\",\n",
    "            \"tariff_rate\": \"N/A\",\n",
    "            \"effective_date\": \"N/A\",\n",
    "            \"included_in_eo\": False\n",
    "        }\n",
    "\n",
    "# Register as a Haystack Tool\n",
    "TariffIQ_tool = create_tool_from_function(get_tariff_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ⚙️ Chat Flow Logic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running OpenAIChatGenerator with Tools\n",
    "\n",
    "To use the tool calling feature, you need to pass the list of tools to `OpenAIChatGenerator` as `tools`. \n",
    "\n",
    "Instruct the model to use provided tools with a system message and then provide a query that requires a tool call as a user message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "user_messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"Use the provided tool to answer questions about tariffs. Do not make assumptions — ask for clarification if the request is ambiguous.\"\n",
    "    ),\n",
    "    ChatMessage.from_user(\"What is the tariff rate for HS Code 8542.31?\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💬 Initialize chat generator\n",
    "chat_generator = OpenAIChatGenerator(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    streaming_callback=print_streaming_chunk\n",
    ")\n",
    "\n",
    "# 🔄 Run chat with tool access\n",
    "response = chat_generator.run(\n",
    "    messages=user_messages,\n",
    "    tools=[TariffIQ_tool]  # 👈 Pass your custom tool here\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use [ToolInvoker](https://docs.haystack.deepset.ai/docs/toolinvoker) to process `ChatMessage` object containing tool calls, invoke the corresponding tools and return the results as a list of `ChatMessage`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Tool result messages: [ChatMessage(_role=<ChatRole.TOOL: 'tool'>, _content=[ToolCallResult(result=\"{'product': 'Electronic integrated circuits - processors and controllers', 'tariff_rate': '25%', 'effective_date': '2025-04-01', 'included_in_eo': True}\", origin=ToolCall(tool_name='get_tariff_info', arguments={'hs_code': '8542.31'}, id='call_huJmjdM3GgUm1mdAC4CJGtxW'), error=False)], _name=None, _meta={})]\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.tools import ToolInvoker\n",
    "\n",
    "# Register your tool (you've already created this)\n",
    "tool_invoker = ToolInvoker(tools=[TariffIQ_tool])\n",
    "\n",
    "# If the model requested a tool call, run the tool and capture results\n",
    "if response[\"replies\"][0].tool_calls:\n",
    "    tool_result_messages = tool_invoker.run(messages=response[\"replies\"])[\"tool_messages\"]\n",
    "    print(f\"🔧 Tool result messages: {tool_result_messages}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, run the `OpenAIChatGenerator` again with the tool call results and get the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tariff rate for HS Code 8542.31, which pertains to electronic integrated circuits (processors and controllers), is 25%. This rate will be effective starting from April 1, 2025.💬 Final answer: The tariff rate for HS Code 8542.31, which pertains to electronic integrated circuits (processors and controllers), is 25%. This rate will be effective starting from April 1, 2025.\n"
     ]
    }
   ],
   "source": [
    "# Combine the system/user messages, AI replies, and tool output\n",
    "messages = user_messages + response[\"replies\"] + tool_result_messages\n",
    "\n",
    "# Run the chat generator again with updated messages and the tool registered\n",
    "final_replies = chat_generator.run(messages=messages, tools=[TariffIQ_tool])[\"replies\"]\n",
    "\n",
    "# Print the final answer\n",
    "print(f\"💬 Final answer: {final_replies[0].text}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 🖥️ Launch with Gradio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Chat Agent\n",
    "\n",
    "As you notice above, OpenAI Chat Completions API does not call the tool; instead, the model generates JSON that you can use to call the tool in your code. That's why, to build an end-to-end chat agent, you need to check if the OpenAI response is a `tool_calls` for every message. If so, you need to call the corresponding tool with the provided arguments and send the tool response back to OpenAI. Otherwise, append both user and messages to the `messages` list to have a regular conversation with the model. Let's build an application that handles all cases.\n",
    "\n",
    "To build a nice UI for your application, you can use [Gradio](https://www.gradio.app/) that comes with a chat interface. Install `gradio`, run the code cell below and use the input box to interact with the chat application that has access to two tools you've created above. \n",
    "\n",
    "> Note: OpenAI models can sometimes hallucinate answers or tools and might not work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /opt/homebrew/lib/python3.11/site-packages (5.23.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (1.25.0)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (2.10.6)\n",
      "Requirement already satisfied: pydub in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.11.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from gradio-client==1.8.0->gradio) (2025.2.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /opt/homebrew/lib/python3.11/site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/vini_jazz/Library/Python/3.11/lib/python/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install -U gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.tools import ToolInvoker\n",
    "\n",
    "# 🔧 Import your tariff tool\n",
    "# from your_module import TariffIQ_tool\n",
    "tool_invoker = ToolInvoker(tools=[TariffIQ_tool])\n",
    "\n",
    "# 💬 Setup Chat Generator with the tool\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\", tools=[TariffIQ_tool])\n",
    "response = None\n",
    "\n",
    "# System instruction\n",
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"Use the tool provided to answer questions about tariffs. Don't make assumptions about inputs. Ask for clarification if needed.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 🧠 Core chatbot logic\n",
    "def chatbot_with_tc(message, history):\n",
    "    global messages\n",
    "    messages.append(ChatMessage.from_user(message))\n",
    "    response = chat_generator.run(messages=messages)\n",
    "\n",
    "    while True:\n",
    "        # 🔁 If the model makes a tool call\n",
    "        if response and response[\"replies\"][0].tool_calls:\n",
    "            tool_result_messages = tool_invoker.run(messages=response[\"replies\"])[\"tool_messages\"]\n",
    "            messages += response[\"replies\"] + tool_result_messages\n",
    "            response = chat_generator.run(messages=messages)\n",
    "        else:\n",
    "            # ✅ Regular response\n",
    "            messages.append(response[\"replies\"][0])\n",
    "            break\n",
    "\n",
    "    return response[\"replies\"][0].text\n",
    "\n",
    "# 💬 Gradio chat app\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot_with_tc,\n",
    "    type=\"messages\",\n",
    "    examples=[\n",
    "        \"What tariffs affect HS Code 8542.31?\",\n",
    "        \"What are the products in our supply list?\",\n",
    "        \"What is the tariff rate of Electronic integrated circuits\",\n",
    "    ],\n",
    "    title=\"💼 TariffIQ — Ask About Trade Policies & Product Impact\",\n",
    "    theme=gr.themes.Ocean(),\n",
    ")\n",
    "\n",
    "# 🚀 Launch\n",
    "demo.launch()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Now It's Your Turn: Build Something Game-Changing\n",
    "\n",
    "🎉 Congrats — you've just built a fully working TariffIQ agent powered by Haystack + OpenAI tools!\n",
    "\n",
    "You're now ready to go from **tutorial** to **real-world impact** — and this is your moment to shine.\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 What You Can Build at the Hackathon:\n",
    "\n",
    "- 🏷️ **Smart HS Code Lookup**  \n",
    "  Let users upload product lists and automatically detect affected tariffs.\n",
    "\n",
    "- 📰 **Executive Order Explainer**  \n",
    "  Ask natural language questions over recent government docs or trade updates.\n",
    "\n",
    "- 📦 **Supply Chain Risk Analyzer**  \n",
    "  Build a chatbot that identifies high-risk suppliers or SKUs based on trade changes.\n",
    "\n",
    "- 💼 **SMB Advisor Bot**  \n",
    "  Help small businesses understand how policy changes affect their import/export pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Tools You Can Use (Beyond This Notebook):\n",
    "- 🧠 [Custom Data Indexing](https://haystack.deepset.ai/tutorials) (PDFs, spreadsheets, APIs)\n",
    "- 🌐 [Cookbooks](https://haystack.deepset.ai/cookbook)\n",
    "- [Model-Based Evaluation of RAG Pipelines](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 🌟 Get Inspired. Get Building. Get Creative.\n",
    "This is your sandbox — bring your ideas to life using Haystack’s modular framework and OpenAI’s tools.\n",
    "To stay up to date on the latest Haystack developments, you can [sign up for our newsletter](https://landing.deepset.ai/haystack-community-updates) or [join Haystack discord community](https://discord.gg/Dr63fr9NDS).\n",
    "\n",
    "Happy Hacking 🎉 🎉 🎉 \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1bdb07730cb146b79d0c0bfd1c9284dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f450b7f47124f8196b3b7714ec77c2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23b57a518b2a4724a807e7d87d84ed6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27424a72441e465ab03699702bf08e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b29f84659637486c97bf97023d2d9c3a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68457ab6ef80409abc692c2591e282c9",
      "value": 1
     }
    },
    "2ec4c8a5f88e485abd8ce946239b59c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30d9aba7738f4d79a5c4d0593d9b6faa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c29df52ee29d4602878f502f14ec121d",
      "placeholder": "​",
      "style": "IPY_MODEL_23b57a518b2a4724a807e7d87d84ed6f",
      "value": "Batches: 100%"
     }
    },
    "31585686320941e79444270287fa3bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bdb07730cb146b79d0c0bfd1c9284dd",
      "placeholder": "​",
      "style": "IPY_MODEL_3be0dedaea4d4a86adf089699d0814a8",
      "value": "Batches: 100%"
     }
    },
    "3be0dedaea4d4a86adf089699d0814a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c191fd5ff34400fa703b24fc09d57e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_825074d7daf54c8f92a0c4637246f904",
      "placeholder": "​",
      "style": "IPY_MODEL_f20aca19ac55499089519e86c8c63d49",
      "value": " 1/1 [00:00&lt;00:00, 14.61it/s]"
     }
    },
    "3f29fa86eea2420587cf3039908cc2e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "466461528ca1456481e860f6202df70c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30d9aba7738f4d79a5c4d0593d9b6faa",
       "IPY_MODEL_27424a72441e465ab03699702bf08e75",
       "IPY_MODEL_e2046da9ab2a4f14b81ac130abf43393"
      ],
      "layout": "IPY_MODEL_85ad1c88c416446fb1df56789c2c65a9"
     }
    },
    "47e025333d33466f802122517f3a584d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "480a7a302d1e45bcb2d54573f3568ad6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5944ad9184ab49aa999b62d152f81fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd6e62494b8745399905a713169f5957",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f450b7f47124f8196b3b7714ec77c2a",
      "value": 1
     }
    },
    "68457ab6ef80409abc692c2591e282c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c23fd14ca8d48c2b63e13c5b599472e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81e44362f359418f96a7fb064124e04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b96969f943d640a699feaa3a4ab28dad",
       "IPY_MODEL_cabee03b724449678cffb53c9e46f630",
       "IPY_MODEL_f59509f2462a4ba387a5c2ff6a6f911a"
      ],
      "layout": "IPY_MODEL_2ec4c8a5f88e485abd8ce946239b59c5"
     }
    },
    "825074d7daf54c8f92a0c4637246f904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ad1c88c416446fb1df56789c2c65a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a40c2224a30a43718f86a08e16c59d7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b29f84659637486c97bf97023d2d9c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b96969f943d640a699feaa3a4ab28dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c495e6700dc3452fa76538ad1d9c1ed8",
      "placeholder": "​",
      "style": "IPY_MODEL_ec769506baec4b5ca99c05d049940a6d",
      "value": "Batches: 100%"
     }
    },
    "bd6e62494b8745399905a713169f5957": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c29df52ee29d4602878f502f14ec121d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c495e6700dc3452fa76538ad1d9c1ed8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cabee03b724449678cffb53c9e46f630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a40c2224a30a43718f86a08e16c59d7e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f29fa86eea2420587cf3039908cc2e6",
      "value": 1
     }
    },
    "ce7ddd5617a44e6eb8fbaf510717d1a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2e3e46dec734d848382ccde2f753a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31585686320941e79444270287fa3bbf",
       "IPY_MODEL_5944ad9184ab49aa999b62d152f81fc0",
       "IPY_MODEL_3c191fd5ff34400fa703b24fc09d57e3"
      ],
      "layout": "IPY_MODEL_480a7a302d1e45bcb2d54573f3568ad6"
     }
    },
    "e2046da9ab2a4f14b81ac130abf43393": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f548b43c34f14120b1f5344a2b5216b7",
      "placeholder": "​",
      "style": "IPY_MODEL_ce7ddd5617a44e6eb8fbaf510717d1a6",
      "value": " 1/1 [00:00&lt;00:00, 19.16it/s]"
     }
    },
    "ec769506baec4b5ca99c05d049940a6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f20aca19ac55499089519e86c8c63d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f548b43c34f14120b1f5344a2b5216b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f59509f2462a4ba387a5c2ff6a6f911a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47e025333d33466f802122517f3a584d",
      "placeholder": "​",
      "style": "IPY_MODEL_7c23fd14ca8d48c2b63e13c5b599472e",
      "value": " 1/1 [00:00&lt;00:00,  2.41it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
